{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0 Testing Accuracy 0.8711Training Accuracy 0.86570907\n",
      "Iter 1 Testing Accuracy 0.9001Training Accuracy 0.8963636\n",
      "Iter 2 Testing Accuracy 0.9097Training Accuracy 0.90583634\n",
      "Iter 3 Testing Accuracy 0.9168Training Accuracy 0.9136364\n",
      "Iter 4 Testing Accuracy 0.9213Training Accuracy 0.9186364\n",
      "Iter 5 Testing Accuracy 0.9253Training Accuracy 0.9224727\n",
      "Iter 6 Testing Accuracy 0.9269Training Accuracy 0.92396367\n",
      "Iter 7 Testing Accuracy 0.9281Training Accuracy 0.92669094\n",
      "Iter 8 Testing Accuracy 0.9291Training Accuracy 0.9281818\n",
      "Iter 9 Testing Accuracy 0.9321Training Accuracy 0.92972726\n",
      "Iter 10 Testing Accuracy 0.9336Training Accuracy 0.93134546\n",
      "Iter 11 Testing Accuracy 0.9351Training Accuracy 0.93347275\n",
      "Iter 12 Testing Accuracy 0.9363Training Accuracy 0.93563634\n",
      "Iter 13 Testing Accuracy 0.9366Training Accuracy 0.9357273\n",
      "Iter 14 Testing Accuracy 0.9355Training Accuracy 0.9368909\n",
      "Iter 15 Testing Accuracy 0.9379Training Accuracy 0.9389091\n",
      "Iter 16 Testing Accuracy 0.9404Training Accuracy 0.93938184\n",
      "Iter 17 Testing Accuracy 0.9394Training Accuracy 0.9407091\n",
      "Iter 18 Testing Accuracy 0.9397Training Accuracy 0.9416\n",
      "Iter 19 Testing Accuracy 0.9408Training Accuracy 0.943\n",
      "Iter 20 Testing Accuracy 0.9411Training Accuracy 0.94305456\n",
      "Iter 21 Testing Accuracy 0.9428Training Accuracy 0.944\n",
      "Iter 22 Testing Accuracy 0.9446Training Accuracy 0.94436365\n",
      "Iter 23 Testing Accuracy 0.9433Training Accuracy 0.94561815\n",
      "Iter 24 Testing Accuracy 0.9452Training Accuracy 0.94692725\n",
      "Iter 25 Testing Accuracy 0.9443Training Accuracy 0.94625455\n",
      "Iter 26 Testing Accuracy 0.9472Training Accuracy 0.9473636\n",
      "Iter 27 Testing Accuracy 0.9466Training Accuracy 0.9482727\n",
      "Iter 28 Testing Accuracy 0.9469Training Accuracy 0.94885457\n",
      "Iter 29 Testing Accuracy 0.9462Training Accuracy 0.95010906\n",
      "Iter 30 Testing Accuracy 0.9483Training Accuracy 0.9502\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([200])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([200, 200], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([200])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([200, 100], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop, W3) + b3)\n",
    "L3_drop = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([100, 10], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop, W4)+b4)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys, keep_prob:0.5})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy, feed_dict={x:mnist.train.images, y:mnist.train.labels, keep_prob:1.0})\n",
    "        print(\"Iter \" + str(epoch) + \" Testing Accuracy \" + str(test_acc) + \"Training Accuracy \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
